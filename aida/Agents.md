# Agents

[TOC]



## Function Tools

Via Function Tooling kann ich eine LLM mit verschiedenen Anwendungen verknüpfen. Dies geschieht, indem die LLM das Aufrufen einer beliebigen API anstößt.

- Bild LLM
- Eigenschaften LLM
  - text in - text out
  - due date 
  - tokens
  - multimodal
  - kein Gedächtnis (kein Memory)
- Beispiel: Wie ist das Wetter heute in London?
- Bild LLM + Function Calling
- Context: Tech Days auf YouTube grafischer Agent Builder von Open AI
- Reasoning erklärt
- Reasoning am Beispiel OpenAI Dashboard
  - Dashboard
  - Open Chat https://platform.openai.com/chat
  - Click Dashboard
  - Create a Chat Prompt (e.g. Code Debugger)
  - 
- OpenAI API Anmeldung
  - API Key erstellen
  - Zahlungsweise hinterlegen
- Function Call
  - json
  - Swagger
  - SSE (Server-Sent Events)
- Beispiele
- Applikation

## Model Context Protocol (MCP) und stdio-Protokoll

KI-Agenten verbinden.



## MCP Streamable Protokoll und Server-Sent Events

## Cloud-Deployment und Sicherheitskonzepte

## Multi-Agentensysteme 

### OpenAI Agent API

### Agent2Agent Protokoll

## Links

[1] Private Chatbots in Azure absichern, Armin Berberovic, iX 02/2025

[2] Function Tools für agentische KI-Systeme entwickeln, Rainer Stropek, heise academy

[3] OpenAI Platform Developer Quickstart, https://platform.openai.com/docs/quickstart?desktop-os=windows, abgerufen am 08.10.2025

[4] OpenAI TypeScript and JavaScript API Library, https://www.npmjs.com/package/openai, abgerufen am 08.10.2025 

[5] Tokenizer, https://platform.openai.com/tokenizer, abgerufen am 08.10.2025

[6] Function Calling with LLMs, https://www.promptingguide.ai/applications/function_calling, abgerufen am 15.10.2025

[7] About MCP, https://modelcontextprotocol.io/docs/getting-started/intro, abgerufen am 15.10.2025

[8] MCP Server Referenz-Implementierung, https://github.com/modelcontextprotocol/servers/tree/main/src/everything, abgerufen am 15.10.2025





